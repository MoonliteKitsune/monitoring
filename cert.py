import requests
import sqlite3
from bs4 import BeautifulSoup

# URL de la page web Ã  analyser
url = "https://www.cert.ssi.gouv.fr/"

# TÃ©lÃ©charger le contenu de la page
response = requests.get(url)

# Parser le contenu HTML avec BeautifulSoup
soup = BeautifulSoup(response.text, "html.parser")

# Trouver le premier Ã©lÃ©ment avec la classe "cert-alert"
first = soup.find(class_="items-list")
date = first.find(class_="item-date")
ref = first.find(class_="item-ref")
titre = first.find(class_="item-title")
status = first.find(class_="item-status")
a=date.text.strip()
b=ref.text.strip()
c=titre.text.strip()
d=status.text.strip()

conn = sqlite3.connect("monitoring.db")
cursor = conn.cursor()

        # CrÃ©ation de la table si elle n'existe pas
cursor.execute("""
CREATE TABLE IF NOT EXISTS alerte (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        date TEXT,
        ref TEXT,
        titre TEXT,
        status TEXT
)
""")

        # InsÃ©rer l'alerte dans la base de donnÃ©es
cursor.execute("INSERT INTO alerte (date, ref, titre, status) VALUES (?, ?, ?, ?)", 
                (a, b, c, d))

conn.commit()
conn.close()

print("âœ… PremiÃ¨re alerte enregistrÃ©e avec succÃ¨s !")
print(f"ðŸ“Œ Titre : {c}")
print(f"ðŸ“Œ ref  : {b}")
print(f"ðŸ“Œ status  : {d}")

